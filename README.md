# Chat-IA-Rag - Assistant IA sur le DiabÃ¨te

Un systÃ¨me RAG (Retrieval-Augmented Generation) avec API FastAPI pour rÃ©pondre aux questions sur le diabÃ¨te en utilisant des sources officielles franÃ§aises et internationales.

## ğŸ“‹ Description

Ce projet combine :
- **Scraping** de donnÃ©es mÃ©dicales depuis des sources officielles
- **RAG (Retrieval-Augmented Generation)** avec LlamaIndex et Groq
- **API REST** avec FastAPI pour interroger le systÃ¨me
- **Ã‰valuation** de la qualitÃ© des rÃ©ponses

## ğŸ—ï¸ Architecture

```
Chat-IA-Rag/
â”œâ”€â”€ Backend/
â”‚   â”œâ”€â”€ main.py                 # API FastAPI
â”‚   â”œâ”€â”€ controller.py           # ContrÃ´leurs de l'API
â”‚   â”œâ”€â”€ crud.py                 # Logique RAG
â”‚   â”œâ”€â”€ schema.py               # SchÃ©mas Pydantic
â”‚   â”œâ”€â”€ model.py                # ModÃ¨les de donnÃ©es
â”‚   â”œâ”€â”€ Scrapping/
â”‚   â”‚   â””â”€â”€ Scrapping.py        # Script de collecte des donnÃ©es
â”‚   â”œâ”€â”€ Test_Model/
â”‚   â”‚   â””â”€â”€ groq_rag.py         # Tests RAG en ligne de commande
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ scraped_data.json   # DonnÃ©es collectÃ©es
â”œâ”€â”€ Frontend/
â”‚   â”œâ”€â”€ index.html              # Interface utilisateur
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css           # Styles Neo-brutalism
â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â””â”€â”€ app.js              # Logique JavaScript
â”‚   â””â”€â”€ serve.py                # Serveur HTTP Python
â”œâ”€â”€ data/                       # Dossier data alternatif
â”œâ”€â”€ .env                        # Configuration (API keys)
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â””â”€â”€ README.md
```

## ğŸ”§ Installation

### PrÃ©requis

- Python 3.8+
- Ollama installÃ© localement (pour les embeddings)
- Compte Groq (pour le LLM)

### Ã‰tapes

1. **Cloner le projet**
```bash
git clone https://github.com/michel97400/Chat-IA-Rag.git
cd Chat-IA-Rag
```

2. **CrÃ©er l'environnement virtuel**
```bash
python -m venv venv
```

3. **Activer l'environnement virtuel**
```bash
# Windows PowerShell
.\venv\Scripts\Activate.ps1

# Windows CMD
.\venv\Scripts\activate.bat

# Linux/Mac
source venv/bin/activate
```

4. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

5. **Installer et configurer Ollama**
```bash
# TÃ©lÃ©charger Ollama depuis https://ollama.ai
# Puis tÃ©lÃ©charger le modÃ¨le d'embeddings
ollama pull bge-m3
```

6. **Configurer les variables d'environnement**

CrÃ©er un fichier `.env` Ã  la racine :
```env
GROQ_API_KEY=votre_clÃ©_api_groq
```

Pour obtenir une clÃ© API Groq : https://console.groq.com

## ğŸš€ Utilisation

### 1. Collecter les donnÃ©es (premiÃ¨re fois uniquement)

```bash
cd Backend/Scrapping
python Scrapping.py
```

â±ï¸ *Temps estimÃ© : 5-10 minutes*

Les donnÃ©es seront sauvegardÃ©es dans `Backend/data/scraped_data.json`

### 2. Lancer l'API FastAPI

```bash
cd Backend
uvicorn main:app --reload
```

L'API sera accessible sur : http://localhost:8000

ğŸ“– Documentation interactive : http://localhost:8000/docs

### 3. Lancer le Frontend

Le frontend dispose d'un serveur Python intÃ©grÃ© pour faciliter le dÃ©veloppement.

```bash
cd Frontend
python serve.py
```

Le frontend sera accessible sur : http://localhost:8080

**Ou utilisez le chemin absolu :**
```bash
python "c:\Users\flavi\OneDrive\Documents\Simplon\Projet\Rag_DiabÃ¨te\Chat-IA-Rag\Frontend\serve.py"
```

**Alternative avec Live Server (VS Code) :**
- Installez l'extension "Live Server" dans VS Code
- Clic droit sur `Frontend/index.html`
- SÃ©lectionnez "Open with Live Server"

### 4. Tester le RAG en ligne de commande (optionnel)

```bash
cd Backend/Test_Model
python groq_rag.py
```

## ğŸ“¡ Endpoints de l'API

### GET `/`
VÃ©rifier le statut de l'API
```bash
curl http://localhost:8000/
```

### POST `/query`
Poser une question au RAG

**Corps de la requÃªte :**
```json
{
  "question": "Quels sont les symptÃ´mes du diabÃ¨te de type 2 ?"
}
```

**Exemple avec curl :**
```bash
curl -X POST "http://localhost:8000/query" \
  -H "Content-Type: application/json" \
  -d '{"question": "Quels sont les symptÃ´mes du diabÃ¨te de type 2 ?"}'
```

**RÃ©ponse :**
```json
{
  "question": "Quels sont les symptÃ´mes du diabÃ¨te de type 2 ?",
  "response": "Les symptÃ´mes du diabÃ¨te de type 2 incluent...",
  "retrieved_docs": [
    {
      "url": "https://...",
      "content": "..."
    }
  ]
}
```

### POST `/evaluate`
Ã‰valuer la qualitÃ© du RAG

**Corps de la requÃªte :**
```json
{
  "question": "Quels sont les symptÃ´mes du diabÃ¨te ?",
  "expected_answer": "Soif intense, fatigue, vision floue..."
}
```

**RÃ©ponse :**
```json
{
  "question": "...",
  "generated_answer": "...",
  "expected_answer": "...",
  "similarity_score": 0.85,
  "evaluation": "Bonne rÃ©ponse"
}
```

## ğŸ§ª Tests rapides

### Tester l'API avec Python

```python
import requests

# Poser une question
response = requests.post(
    "http://localhost:8000/query",
    json={"question": "Quelle est la prÃ©valence du diabÃ¨te en France ?"}
)
print(response.json())
```

### Tester avec PowerShell

```powershell
$body = @{
    question = "Quels sont les facteurs de risque du diabÃ¨te ?"
} | ConvertTo-Json

Invoke-RestMethod -Uri "http://localhost:8000/query" `
  -Method Post `
  -ContentType "application/json" `
  -Body $body
```

## ğŸ“Š Sources de donnÃ©es

Le systÃ¨me collecte des informations depuis :

- **SantÃ© Publique France** : DonnÃ©es Ã©pidÃ©miologiques
- **Haute AutoritÃ© de SantÃ© (HAS)** : Recommandations cliniques
- **INSERM** : Recherche mÃ©dicale
- **OMS** : Statistiques mondiales
- **FÃ©dÃ©ration FranÃ§aise des DiabÃ©tiques** : Information patients
- Et 25+ autres sources officielles

## ğŸ› ï¸ Technologies utilisÃ©es

- **FastAPI** : Framework web moderne
- **LlamaIndex** : Framework RAG
- **Groq** : LLM (Llama 3.3 70B)
- **Ollama** : Embeddings locaux (BGE-M3)
- **Trafilatura** : Scraping web
- **scikit-learn** : Ã‰valuation des rÃ©ponses

## ğŸ“ Structure de l'API

### Fichiers principaux

- **main.py** : Point d'entrÃ©e de l'API FastAPI
- **controller.py** : Gestion des endpoints
- **crud.py** : Logique RAG (crÃ©ation index, recherche, gÃ©nÃ©ration)
- **schema.py** : SchÃ©mas de validation des requÃªtes/rÃ©ponses
- **model.py** : ModÃ¨les de donnÃ©es

## ğŸ” DÃ©pannage

### Erreur "GROQ_API_KEY non trouvÃ©e"
- VÃ©rifiez que le fichier `.env` existe Ã  la racine
- VÃ©rifiez que la clÃ© API est correcte

### Erreur "Ollama not found"
- Assurez-vous qu'Ollama est installÃ© et en cours d'exÃ©cution
- Lancez `ollama serve` dans un terminal sÃ©parÃ©

### Erreur "scraped_data.json non trouvÃ©"
- Lancez d'abord le script de scraping
- VÃ©rifiez que le fichier est dans `Backend/data/`

### L'API ne dÃ©marre pas
```bash
# VÃ©rifier que le port 8000 est libre
netstat -ano | findstr :8000

# Ou utiliser un autre port
uvicorn main:app --port 8080
```

## ğŸš€ Commandes utiles

### Backend (API)
```bash
# Lancer l'API en mode dÃ©veloppement
cd Backend
uvicorn main:app --reload

# Lancer l'API en production
uvicorn main:app --host 0.0.0.0 --port 8000

# Voir les logs dÃ©taillÃ©s
uvicorn main:app --log-level debug

# Lancer le scraping
cd Backend/Scrapping
python Scrapping.py

# Tester le RAG en CLI
cd Backend/Test_Model
python groq_rag.py
```

### Frontend
```bash
# Lancer le serveur Frontend (port 8080)
cd Frontend
python serve.py

# Ou avec chemin absolu
python "c:\...\Chat-IA-Rag\Frontend\serve.py"
```

### Utilisation complÃ¨te
1. **Terminal 1** : Lancer l'API Backend
   ```bash
   cd Backend
   uvicorn main:app --reload
   ```

2. **Terminal 2** : Lancer le Frontend
   ```bash
   cd Frontend
   python serve.py
   ```

3. **Navigateur** : Ouvrir http://localhost:8080

## ğŸ“š Documentation

- Documentation API : http://localhost:8000/docs
- Documentation alternative : http://localhost:8000/redoc
- Groq API : https://console.groq.com/docs
- LlamaIndex : https://docs.llamaindex.ai/

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  ouvrir une issue ou une pull request.

## âš ï¸ Avertissement

Ce systÃ¨me est un outil d'information uniquement. Il ne remplace pas l'avis d'un professionnel de santÃ©. Consultez toujours un mÃ©decin pour toute question mÃ©dicale.